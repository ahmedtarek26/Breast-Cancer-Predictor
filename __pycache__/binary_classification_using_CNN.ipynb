{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "binary classification using CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77dMbdgPs1S8",
        "outputId": "9afc5c02-8b8e-49ef-8de5-03f40a13ed2c"
      },
      "source": [
        "from zipfile import ZipFile \n",
        "file_name = 'BCP_Image_Dataset.zip'\n",
        "\n",
        "with ZipFile(file_name,'r')as zip:\n",
        "  zip.extractall()\n",
        "  print('done')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7A6HpfRW05_"
      },
      "source": [
        "# Imports needed\n",
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl61En3GXJ2u"
      },
      "source": [
        "img_height = 28\n",
        "img_width = 28\n",
        "batch_size = 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wIAjrPPXOWe"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Input((28, 28, 1)),\n",
        "        layers.Conv2D(16, 3, padding=\"same\"),\n",
        "        layers.Conv2D(32, 3, padding=\"same\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GYssCoQXU8T",
        "outputId": "2d6fb7fe-6c0b-4617-e0e8-f9209ebbcb5a"
      },
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/BCP_Image_Dataset',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\", \n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),  # reshape if not in this size\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.1,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/BCP_Image_Dataset\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_height, img_width),  # reshape if not in this size\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\"\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 933 files belonging to 2 classes.\n",
            "Using 840 files for training.\n",
            "Found 933 files belonging to 2 classes.\n",
            "Using 93 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIiDIqz9XYRs",
        "outputId": "3449927a-d517-4be6-b661-298c59413f5d"
      },
      "source": [
        "def augment(x, y):\n",
        "    image = tf.image.random_brightness(x, max_delta=0.05)\n",
        "    return image, y\n",
        "\n",
        "\n",
        "ds_train = ds_train.map(augment)\n",
        "\n",
        "# Custom Loops\n",
        "for epochs in range(10):\n",
        "    for x, y in ds_train:\n",
        "        # train here\n",
        "        pass\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "print(model.summary())    \n",
        "\n",
        "\n",
        "model.fit(ds_train, epochs=10, verbose=2)  # you can change number of epochs"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 6273      \n",
            "=================================================================\n",
            "Total params: 11,073\n",
            "Trainable params: 11,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "420/420 - 6s - loss: 7.7903 - accuracy: 0.4905\n",
            "Epoch 2/10\n",
            "420/420 - 6s - loss: 7.6994 - accuracy: 0.4964\n",
            "Epoch 3/10\n",
            "420/420 - 6s - loss: 7.6994 - accuracy: 0.4964\n",
            "Epoch 4/10\n",
            "420/420 - 6s - loss: 7.4113 - accuracy: 0.5143\n",
            "Epoch 5/10\n",
            "420/420 - 6s - loss: 6.7019 - accuracy: 0.5655\n",
            "Epoch 6/10\n",
            "420/420 - 6s - loss: 6.7019 - accuracy: 0.5655\n",
            "Epoch 7/10\n",
            "420/420 - 6s - loss: 6.7019 - accuracy: 0.5655\n",
            "Epoch 8/10\n",
            "420/420 - 6s - loss: 6.7019 - accuracy: 0.5655\n",
            "Epoch 9/10\n",
            "420/420 - 6s - loss: 6.7019 - accuracy: 0.5655\n",
            "Epoch 10/10\n",
            "420/420 - 6s - loss: 6.7019 - accuracy: 0.5655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f549d8616d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYhCd58JdcGP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}